{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "import yaml\n",
    "import math\n",
    "from collections import Counter\n",
    "sys.path.append('.')\n",
    "sys.path.append('./..')\n",
    "import model_file\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_initial_entity_embeddings(\n",
    "    data_file='train_data.csv',\n",
    "    model_data_save_dir='.',\n",
    "    id_col = 'PanjivaRecordID'\n",
    "):\n",
    "    train_df = pd.read_csv(data_file)\n",
    "    feature_cols = sorted(list(train_df.columns))\n",
    "    feature_cols = list(feature_cols)\n",
    "    feature_cols.remove(id_col)\n",
    "    domains = feature_cols\n",
    "\n",
    "    data = train_df[feature_cols].values\n",
    "    nd = len(feature_cols)\n",
    "    num_c = nd *(nd-1) // 2\n",
    "\n",
    "    with open(\"coOccMatrix_dict.pkl\",'rb') as fh:\n",
    "        coOccMatrix_dict = pickle.load( fh )\n",
    "\n",
    "    with open(\"domain_dims.pkl\",'rb') as fh:\n",
    "        domain_dims = pickle.load( fh )\n",
    "\n",
    "    # ===== \n",
    "    # Ensure X_ij is in aflattened format ; i < j\n",
    "    # =====\n",
    "    if os.path.exists(\"X_ij.pkl\") :\n",
    "        with open(\"X_ij.pkl\",\"rb\") as fh:\n",
    "            X_ij = pickle.load(fh)\n",
    "    else:\n",
    "\n",
    "        X_ij = np.zeros([data.shape[0], num_c ])\n",
    "        k = 0\n",
    "        for i in range(len(feature_cols)):\n",
    "            for j in range(i+1, len(feature_cols)):\n",
    "                key = feature_cols[i]+ '_+_' + feature_cols[j]\n",
    "                for d in range(data.shape[0]):\n",
    "                    e1 = data[d][i]\n",
    "                    e2 = data[d][j]\n",
    "                    X_ij[d][k] = coOccMatrix_dict[key][e1][e2]\n",
    "                k+=1\n",
    "\n",
    "        with open(\"X_ij.pkl\",\"wb\") as fh:\n",
    "            pickle.dump(X_ij,fh,pickle.HIGHEST_PROTOCOL)             \n",
    "\n",
    "    # X_ij_max needed for scaling \n",
    "    X_ij_max = []\n",
    "    for k,v in coOccMatrix_dict.items():\n",
    "        X_ij_max.append(np.max(v))\n",
    "\n",
    "    model = model_file.get_model(\n",
    "        domain_dimesnsions = list(domain_dims.values()),\n",
    "        num_domains = 4,\n",
    "        embed_dim = 256,\n",
    "        _X_ij_max = X_ij_max\n",
    "    )\n",
    "\n",
    "    model_file.train_model(\n",
    "        model,\n",
    "        data,\n",
    "        X_ij,\n",
    "        epochs = 500\n",
    "    )\n",
    "\n",
    "    # ----\n",
    "    # Save the embeddings (weights) in a dictionary\n",
    "    # ----\n",
    "    emb_w = {}\n",
    "    for i in range(len(feature_cols)):\n",
    "        dom = feature_cols[i]\n",
    "        w = np.load('embedding_w_{}.npy'.format(i))\n",
    "        emb_w[dom] = w\n",
    "\n",
    "    # ================== \n",
    "    # Following GloVe\n",
    "    # emb ( entity = E in D)\n",
    "    #  x = 0\n",
    "    #  For d in {Doamian} - D\n",
    "    #     x += Sum (CoOcc( E, E_d`)/max(CoOcc( E, E_d`)) *  emb ( entity = E ))\n",
    "    #  x = 1/2(emb_old(E) + x)\n",
    "    # ==================\n",
    "\n",
    "    new_embeddings = {}\n",
    "    for domain_i in domains:\n",
    "        new_embeddings[domain_i] = np.zeros(\n",
    "            emb_w[domain_i].shape\n",
    "        )\n",
    "                      \n",
    "        domain_dim = domain_dims[domain_i]\n",
    "        # For each entity in domain i \n",
    "        for entity_id in range(domain_dim):\n",
    "            res = 0\n",
    "            # For each entity in domain j != i\n",
    "            for domain_j in domains:\n",
    "                if domain_j == domain_i : continue    \n",
    "                pair = sorted([domain_i,domain_j])\n",
    "\n",
    "                key = '_+_'.join(pair)\n",
    "                coOcc_matrix = coOccMatrix_dict[key]\n",
    "                if domain_i == pair[0]:\n",
    "                    arr = coOcc_matrix[entity_id,:]\n",
    "                else:\n",
    "                    arr = coOcc_matrix[:,entity_id]\n",
    "                      \n",
    "                sum_co_occ = max(np.sum(arr),1)\n",
    "                scale = np.reshape(arr/sum_co_occ,[-1,1])\n",
    "\n",
    "                emb_domain_j = emb_w[domain_j]\n",
    "                res_j = np.sum(scale * emb_domain_j,axis=0)\n",
    "                res =  res + res_j\n",
    "\n",
    "            res = 0.5 *( res + emb_w[domain_i][entity_id] )\n",
    "            new_embeddings[domain_i][entity_id] = res\n",
    "\n",
    "    # Write the embeddings to file \n",
    "    for d in domains:\n",
    "        print(' >> ', d) \n",
    "        file_name = os.path.join(\n",
    "            model_data_save_dir,\n",
    "            'init_embedding' + d + '.npy'\n",
    "        )\n",
    "        np.save(\n",
    "            file = file_name, \n",
    "            arr = new_embeddings[domain_i]\n",
    "        )\n",
    "    \n",
    "    def test():\n",
    "        hscode = 25\n",
    "        # find the 10 closest  to ShipmentDestination to HSCode in data\n",
    "        df = train_df.loc[train_df['HSCode']==hscode]\n",
    "        df = df.groupby(['HSCode','ShipmentDestination']).size().reset_index(name='counts')\n",
    "        df = df.sort_values(by=['counts'])\n",
    "\n",
    "        k_closest = df.tail(10)['ShipmentDestination'].values\n",
    "        print(k_closest)\n",
    "\n",
    "        # hs_code_vec = wt[0][hscode] + bias[0][hscode]\n",
    "        hs_code_vec = new_embeddings['HSCode'][hscode]\n",
    "\n",
    "        shp_dest_vec = []\n",
    "        wt = new_embeddings['ShipmentDestination']\n",
    "        for i in range(wt.shape[0]):\n",
    "            r = wt[i] \n",
    "            shp_dest_vec.append(r)\n",
    "\n",
    "        res = { }\n",
    "        for i in range(wt.shape[0]):\n",
    "            a = np.reshape(shp_dest_vec[i],[1,-1])\n",
    "            b = np.reshape(hs_code_vec,[1,-1])\n",
    "            res[i] = cosine_similarity(a,b)\n",
    "\n",
    "        new_df = pd.DataFrame(list(res.items()))\n",
    "        new_df = new_df.sort_values(by=[1])\n",
    "        print(new_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/skunk02/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/skunk02/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/skunk02/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/skunk02/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "split_layer (Lambda)            [(None, 1), (None, 1 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_w_0 (Embedding)       (None, 1, 256)       14592       split_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_w_1 (Embedding)       (None, 1, 256)       7680        split_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_w_2 (Embedding)       (None, 1, 256)       23296       split_layer[0][2]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_w_3 (Embedding)       (None, 1, 256)       768         split_layer[0][3]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 1)         0           embedding_w_0[0][0]              \n",
      "                                                                 embedding_w_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 1, 1)         0           embedding_w_0[0][0]              \n",
      "                                                                 embedding_w_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 1, 1)         0           embedding_w_0[0][0]              \n",
      "                                                                 embedding_w_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 1, 1)         0           embedding_w_1[0][0]              \n",
      "                                                                 embedding_w_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_5 (Dot)                     (None, 1, 1)         0           embedding_w_1[0][0]              \n",
      "                                                                 embedding_w_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_6 (Dot)                     (None, 1, 1)         0           embedding_w_2[0][0]              \n",
      "                                                                 embedding_w_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1)            0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_b_0 (Embedding)       (None, 1, 1)         57          split_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_b_1 (Embedding)       (None, 1, 1)         30          split_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1)            0           dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_b_2 (Embedding)       (None, 1, 1)         91          split_layer[0][2]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1)            0           dot_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_b_3 (Embedding)       (None, 1, 1)         3           split_layer[0][3]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1)            0           dot_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1)            0           dot_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 1)            0           dot_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1, 1)         0           reshape_1[0][0]                  \n",
      "                                                                 embedding_b_0[0][0]              \n",
      "                                                                 embedding_b_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1, 1)         0           reshape_3[0][0]                  \n",
      "                                                                 embedding_b_0[0][0]              \n",
      "                                                                 embedding_b_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1, 1)         0           reshape_5[0][0]                  \n",
      "                                                                 embedding_b_0[0][0]              \n",
      "                                                                 embedding_b_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 1, 1)         0           reshape_7[0][0]                  \n",
      "                                                                 embedding_b_1[0][0]              \n",
      "                                                                 embedding_b_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 1, 1)         0           reshape_9[0][0]                  \n",
      "                                                                 embedding_b_1[0][0]              \n",
      "                                                                 embedding_b_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 1, 1)         0           reshape_11[0][0]                 \n",
      "                                                                 embedding_b_2[0][0]              \n",
      "                                                                 embedding_b_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1)            0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1)            0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1)            0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1)            0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1)            0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 1)            0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stack_layer (Lambda)            (None, 6, 1)         0           reshape_2[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_10[0][0]                 \n",
      "                                                                 reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_layer (Lambda)          (None, 6)            0           stack_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 46,517\n",
      "Trainable params: 46,517\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/skunk02/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/skunk02/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/skunk02/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/skunk02/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/skunk02/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/skunk02/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/skunk02/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/skunk02/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2578/2578 [==============================] - 2s 598us/step - loss: 65.1780\n",
      "Epoch 2/500\n",
      "2578/2578 [==============================] - 0s 68us/step - loss: 39.9773\n",
      "Epoch 3/500\n",
      "2578/2578 [==============================] - 0s 67us/step - loss: 9.4096\n",
      "Epoch 4/500\n",
      "2578/2578 [==============================] - 0s 62us/step - loss: 0.5955\n",
      "Epoch 5/500\n",
      "2578/2578 [==============================] - 0s 61us/step - loss: 0.2008\n",
      "Epoch 6/500\n",
      "2578/2578 [==============================] - 0s 68us/step - loss: 0.1224\n",
      "Epoch 7/500\n",
      "2578/2578 [==============================] - 0s 72us/step - loss: 0.0872\n",
      "Epoch 8/500\n",
      "2578/2578 [==============================] - 0s 77us/step - loss: 0.0673\n",
      "Epoch 9/500\n",
      "2578/2578 [==============================] - 0s 77us/step - loss: 0.0547\n",
      "Epoch 10/500\n",
      "2578/2578 [==============================] - 0s 71us/step - loss: 0.0461\n",
      "Epoch 11/500\n",
      "2578/2578 [==============================] - 0s 77us/step - loss: 0.0400\n",
      "Epoch 12/500\n",
      "2578/2578 [==============================] - 0s 132us/step - loss: 0.0355\n",
      "Epoch 13/500\n",
      "2578/2578 [==============================] - 0s 119us/step - loss: 0.0321\n",
      "Epoch 14/500\n",
      "2578/2578 [==============================] - 0s 111us/step - loss: 0.0293\n",
      "Epoch 15/500\n",
      "2578/2578 [==============================] - 0s 105us/step - loss: 0.0269\n",
      "Epoch 16/500\n",
      "2578/2578 [==============================] - 0s 133us/step - loss: 0.0249\n",
      "Epoch 17/500\n",
      "2578/2578 [==============================] - 0s 148us/step - loss: 0.0230\n",
      "Epoch 18/500\n",
      "2578/2578 [==============================] - 1s 275us/step - loss: 0.0214\n",
      "Epoch 19/500\n",
      "2578/2578 [==============================] - 1s 276us/step - loss: 0.0199\n",
      "Epoch 20/500\n",
      "2578/2578 [==============================] - 0s 164us/step - loss: 0.0184\n",
      "Epoch 21/500\n",
      "2578/2578 [==============================] - 1s 406us/step - loss: 0.0171\n",
      "Epoch 22/500\n",
      "2578/2578 [==============================] - 1s 412us/step - loss: 0.0160\n",
      "Epoch 23/500\n",
      "2578/2578 [==============================] - 2s 741us/step - loss: 0.0149\n",
      "Epoch 24/500\n",
      "2578/2578 [==============================] - 1s 335us/step - loss: 0.0139\n",
      "Epoch 25/500\n",
      "2578/2578 [==============================] - 1s 247us/step - loss: 0.0130\n",
      "Epoch 26/500\n",
      "2578/2578 [==============================] - 1s 236us/step - loss: 0.0122\n",
      "Epoch 27/500\n",
      "2578/2578 [==============================] - 0s 157us/step - loss: 0.0115\n",
      "Epoch 28/500\n",
      "2578/2578 [==============================] - 0s 149us/step - loss: 0.0108\n",
      "Epoch 29/500\n",
      "2578/2578 [==============================] - 0s 174us/step - loss: 0.0102\n",
      "Epoch 30/500\n",
      "2578/2578 [==============================] - 0s 131us/step - loss: 0.0096\n",
      "Epoch 31/500\n",
      "2578/2578 [==============================] - 0s 136us/step - loss: 0.0090\n",
      "Epoch 32/500\n",
      "2578/2578 [==============================] - 0s 102us/step - loss: 0.0086\n",
      "Epoch 33/500\n",
      "2578/2578 [==============================] - 0s 114us/step - loss: 0.0081\n",
      "Epoch 34/500\n",
      "2578/2578 [==============================] - 0s 121us/step - loss: 0.0077\n",
      "Epoch 35/500\n",
      "2578/2578 [==============================] - 0s 103us/step - loss: 0.0073\n",
      "Epoch 36/500\n",
      "2578/2578 [==============================] - 0s 108us/step - loss: 0.0069\n",
      "Epoch 37/500\n",
      "2578/2578 [==============================] - 0s 109us/step - loss: 0.0066\n",
      "Epoch 38/500\n",
      "2578/2578 [==============================] - 0s 106us/step - loss: 0.0063\n",
      "Epoch 39/500\n",
      "2578/2578 [==============================] - 0s 87us/step - loss: 0.0060\n",
      "Epoch 40/500\n",
      "2578/2578 [==============================] - 0s 83us/step - loss: 0.0057\n",
      "Epoch 41/500\n",
      "2578/2578 [==============================] - 0s 87us/step - loss: 0.0054\n",
      "Epoch 42/500\n",
      "2578/2578 [==============================] - 0s 90us/step - loss: 0.0052\n",
      "Epoch 43/500\n",
      "2578/2578 [==============================] - 0s 96us/step - loss: 0.0050\n",
      "Epoch 44/500\n",
      "2578/2578 [==============================] - 0s 94us/step - loss: 0.0047\n",
      "Epoch 45/500\n",
      "2578/2578 [==============================] - 0s 97us/step - loss: 0.0045\n",
      "Epoch 46/500\n",
      "2578/2578 [==============================] - 0s 98us/step - loss: 0.0043\n",
      "Epoch 47/500\n",
      "2578/2578 [==============================] - 0s 66us/step - loss: 0.0041\n",
      "Epoch 48/500\n",
      "2578/2578 [==============================] - 0s 65us/step - loss: 0.0039\n",
      "Epoch 49/500\n",
      "2578/2578 [==============================] - 0s 79us/step - loss: 0.0038\n",
      "Epoch 50/500\n",
      "2578/2578 [==============================] - 0s 77us/step - loss: 0.0036\n",
      "Epoch 51/500\n",
      "2578/2578 [==============================] - 0s 66us/step - loss: 0.0035\n",
      "Epoch 52/500\n",
      "2578/2578 [==============================] - 0s 76us/step - loss: 0.0033\n",
      "Epoch 53/500\n",
      "2578/2578 [==============================] - 0s 61us/step - loss: 0.0032\n",
      "Epoch 54/500\n",
      "2578/2578 [==============================] - 0s 81us/step - loss: 0.0030\n",
      "Epoch 55/500\n",
      "2578/2578 [==============================] - 0s 72us/step - loss: 0.0029\n",
      "Epoch 56/500\n",
      "2578/2578 [==============================] - 0s 87us/step - loss: 0.0028\n",
      "Epoch 57/500\n",
      "2578/2578 [==============================] - 0s 62us/step - loss: 0.0027\n",
      "Epoch 58/500\n",
      "2578/2578 [==============================] - 0s 80us/step - loss: 0.0026\n",
      "Epoch 59/500\n",
      "2578/2578 [==============================] - 0s 67us/step - loss: 0.0024\n",
      "Epoch 60/500\n",
      "2578/2578 [==============================] - 0s 71us/step - loss: 0.0023\n",
      "Epoch 61/500\n",
      "2578/2578 [==============================] - 0s 69us/step - loss: 0.0022\n",
      "Epoch 62/500\n",
      "2578/2578 [==============================] - 0s 59us/step - loss: 0.0022\n",
      "Epoch 63/500\n",
      "2578/2578 [==============================] - 0s 59us/step - loss: 0.0021\n",
      "Epoch 64/500\n",
      "2578/2578 [==============================] - 0s 61us/step - loss: 0.0020\n",
      "Epoch 65/500\n",
      "2578/2578 [==============================] - 0s 70us/step - loss: 0.0019\n",
      "Epoch 66/500\n",
      "2578/2578 [==============================] - 0s 51us/step - loss: 0.0018\n",
      "Epoch 67/500\n",
      "2578/2578 [==============================] - 0s 60us/step - loss: 0.0018\n",
      "Epoch 68/500\n",
      "2578/2578 [==============================] - 0s 60us/step - loss: 0.0017\n",
      "Epoch 69/500\n",
      "2578/2578 [==============================] - 0s 55us/step - loss: 0.0016\n",
      "Epoch 70/500\n",
      "2578/2578 [==============================] - 0s 51us/step - loss: 0.0016\n",
      "Epoch 71/500\n",
      "2578/2578 [==============================] - 0s 46us/step - loss: 0.0015\n",
      "Epoch 72/500\n",
      "2578/2578 [==============================] - 0s 51us/step - loss: 0.0015\n",
      "Epoch 73/500\n",
      "2578/2578 [==============================] - 0s 56us/step - loss: 0.0014\n",
      "Epoch 74/500\n",
      "2578/2578 [==============================] - 0s 68us/step - loss: 0.0014\n",
      "Epoch 75/500\n",
      "2578/2578 [==============================] - 0s 53us/step - loss: 0.0013\n",
      "Epoch 76/500\n",
      "2578/2578 [==============================] - 0s 48us/step - loss: 0.0013\n",
      "Epoch 77/500\n",
      "2578/2578 [==============================] - 0s 57us/step - loss: 0.0012\n",
      "Epoch 78/500\n",
      "2578/2578 [==============================] - 0s 54us/step - loss: 0.0012\n",
      "Epoch 79/500\n",
      "2578/2578 [==============================] - 0s 59us/step - loss: 0.0012\n",
      "Epoch 80/500\n",
      "2578/2578 [==============================] - 0s 44us/step - loss: 0.0011\n",
      "Epoch 81/500\n",
      "2578/2578 [==============================] - 0s 50us/step - loss: 0.0011\n",
      "Epoch 82/500\n",
      "2578/2578 [==============================] - 0s 58us/step - loss: 0.0010\n",
      "Epoch 83/500\n",
      "2578/2578 [==============================] - 0s 49us/step - loss: 0.0010\n",
      "Epoch 84/500\n",
      "2578/2578 [==============================] - 0s 43us/step - loss: 9.7765e-04\n",
      "Epoch 85/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 9.4851e-04\n",
      "Epoch 86/500\n",
      "2578/2578 [==============================] - 0s 41us/step - loss: 9.1835e-04\n",
      "Epoch 87/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 8.8871e-04\n",
      "Epoch 88/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 8.5447e-04\n",
      "Epoch 89/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 8.2546e-04\n",
      "Epoch 90/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 8.0749e-04\n",
      "Epoch 91/500\n",
      "2578/2578 [==============================] - 0s 42us/step - loss: 7.8531e-04\n",
      "Epoch 92/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 7.5847e-04\n",
      "Epoch 93/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 7.7285e-04\n",
      "Epoch 94/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 7.1791e-04\n",
      "Epoch 95/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 6.9156e-04\n",
      "Epoch 96/500\n",
      "2578/2578 [==============================] - 0s 45us/step - loss: 6.6136e-04\n",
      "Epoch 97/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 6.3930e-04\n",
      "Epoch 98/500\n",
      "2578/2578 [==============================] - 0s 41us/step - loss: 6.2692e-04\n",
      "Epoch 99/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 6.1622e-04\n",
      "Epoch 100/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 6.0127e-04\n",
      "Epoch 101/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 5.6291e-04\n",
      "Epoch 102/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 5.4360e-04\n",
      "Epoch 103/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 5.2594e-04\n",
      "Epoch 104/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 5.2202e-04\n",
      "Epoch 105/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 4.9855e-04\n",
      "Epoch 106/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 4.9391e-04\n",
      "Epoch 107/500\n",
      "2578/2578 [==============================] - 0s 44us/step - loss: 4.7962e-04\n",
      "Epoch 108/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 4.6487e-04\n",
      "Epoch 109/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 4.3517e-04\n",
      "Epoch 110/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 4.1349e-04\n",
      "Epoch 111/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 3.9320e-04\n",
      "Epoch 112/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 3.9146e-04\n",
      "Epoch 113/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 3.7137e-04\n",
      "Epoch 114/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 3.8918e-04\n",
      "Epoch 115/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 3.6737e-04\n",
      "Epoch 116/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 3.5793e-04\n",
      "Epoch 117/500\n",
      "2578/2578 [==============================] - 0s 44us/step - loss: 3.1696e-04\n",
      "Epoch 118/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 3.2587e-04\n",
      "Epoch 119/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 3.1985e-04\n",
      "Epoch 120/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 3.2435e-04\n",
      "Epoch 121/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 2.9881e-04\n",
      "Epoch 122/500\n",
      "2578/2578 [==============================] - 0s 41us/step - loss: 2.8839e-04\n",
      "Epoch 123/500\n",
      "2578/2578 [==============================] - 0s 49us/step - loss: 2.6132e-04\n",
      "Epoch 124/500\n",
      "2578/2578 [==============================] - 0s 49us/step - loss: 2.8929e-04\n",
      "Epoch 125/500\n",
      "2578/2578 [==============================] - 0s 50us/step - loss: 2.8146e-04\n",
      "Epoch 126/500\n",
      "2578/2578 [==============================] - 0s 59us/step - loss: 2.8374e-04\n",
      "Epoch 127/500\n",
      "2578/2578 [==============================] - 0s 53us/step - loss: 2.6277e-04\n",
      "Epoch 128/500\n",
      "2578/2578 [==============================] - 0s 49us/step - loss: 2.2433e-04\n",
      "Epoch 129/500\n",
      "2578/2578 [==============================] - 0s 50us/step - loss: 2.2133e-04\n",
      "Epoch 130/500\n",
      "2578/2578 [==============================] - 0s 49us/step - loss: 3.0151e-04\n",
      "Epoch 131/500\n",
      "2578/2578 [==============================] - 0s 50us/step - loss: 2.1872e-04\n",
      "Epoch 132/500\n",
      "2578/2578 [==============================] - 0s 50us/step - loss: 2.0472e-04\n",
      "Epoch 133/500\n",
      "2578/2578 [==============================] - 0s 49us/step - loss: 1.8758e-04\n",
      "Epoch 134/500\n",
      "2578/2578 [==============================] - 0s 57us/step - loss: 2.1595e-04\n",
      "Epoch 135/500\n",
      "2578/2578 [==============================] - 0s 54us/step - loss: 1.7836e-04\n",
      "Epoch 136/500\n",
      "2578/2578 [==============================] - 0s 50us/step - loss: 1.6827e-04\n",
      "Epoch 137/500\n",
      "2578/2578 [==============================] - 0s 71us/step - loss: 2.6103e-04\n",
      "Epoch 138/500\n",
      "2578/2578 [==============================] - 0s 76us/step - loss: 2.8750e-04\n",
      "Epoch 139/500\n",
      "2578/2578 [==============================] - 0s 84us/step - loss: 1.6010e-04\n",
      "Epoch 140/500\n",
      "2578/2578 [==============================] - 0s 97us/step - loss: 1.6193e-04\n",
      "Epoch 141/500\n",
      "2578/2578 [==============================] - 0s 72us/step - loss: 1.7297e-04\n",
      "Epoch 142/500\n",
      "2578/2578 [==============================] - 0s 74us/step - loss: 1.8925e-04\n",
      "Epoch 143/500\n",
      "2578/2578 [==============================] - 0s 75us/step - loss: 1.6220e-04\n",
      "Epoch 144/500\n",
      "2578/2578 [==============================] - 0s 87us/step - loss: 1.5539e-04\n",
      "Epoch 145/500\n",
      "2578/2578 [==============================] - 0s 73us/step - loss: 1.3587e-04\n",
      "Epoch 146/500\n",
      "2578/2578 [==============================] - 0s 100us/step - loss: 2.1528e-04\n",
      "Epoch 147/500\n",
      "2578/2578 [==============================] - 0s 170us/step - loss: 1.3667e-04\n",
      "Epoch 148/500\n",
      "2578/2578 [==============================] - 0s 186us/step - loss: 1.4390e-04\n",
      "Epoch 149/500\n",
      "2578/2578 [==============================] - 0s 167us/step - loss: 2.1495e-04\n",
      "Epoch 150/500\n",
      "2578/2578 [==============================] - 0s 179us/step - loss: 1.6485e-04\n",
      "Epoch 151/500\n",
      "2578/2578 [==============================] - 1s 502us/step - loss: 1.4818e-04\n",
      "Epoch 152/500\n",
      "2578/2578 [==============================] - 1s 353us/step - loss: 1.2847e-04\n",
      "Epoch 153/500\n",
      "2578/2578 [==============================] - 0s 167us/step - loss: 1.5815e-04\n",
      "Epoch 154/500\n",
      "2578/2578 [==============================] - 0s 172us/step - loss: 1.2502e-04\n",
      "Epoch 155/500\n",
      "2578/2578 [==============================] - 1s 268us/step - loss: 1.3436e-04\n",
      "Epoch 156/500\n",
      "2578/2578 [==============================] - 0s 171us/step - loss: 1.9812e-04\n",
      "Epoch 157/500\n",
      "2578/2578 [==============================] - 0s 136us/step - loss: 1.6143e-04\n",
      "Epoch 158/500\n",
      "2578/2578 [==============================] - 0s 138us/step - loss: 3.8904e-04\n",
      "Epoch 159/500\n",
      "2578/2578 [==============================] - 0s 153us/step - loss: 1.2915e-04\n",
      "Epoch 160/500\n",
      "2578/2578 [==============================] - 0s 148us/step - loss: 2.2610e-04\n",
      "Epoch 161/500\n",
      "2578/2578 [==============================] - 0s 149us/step - loss: 2.2088e-04\n",
      "Epoch 162/500\n",
      "2578/2578 [==============================] - 0s 117us/step - loss: 1.2475e-04\n",
      "Epoch 163/500\n",
      "2578/2578 [==============================] - 0s 97us/step - loss: 1.1082e-04\n",
      "Epoch 164/500\n",
      "2578/2578 [==============================] - 0s 113us/step - loss: 7.3219e-04\n",
      "Epoch 165/500\n",
      "2578/2578 [==============================] - 0s 110us/step - loss: 2.5881e-04\n",
      "Epoch 166/500\n",
      "2578/2578 [==============================] - 0s 101us/step - loss: 1.5844e-04\n",
      "Epoch 167/500\n",
      "2578/2578 [==============================] - 0s 114us/step - loss: 1.2381e-04\n",
      "Epoch 168/500\n",
      "2578/2578 [==============================] - 0s 101us/step - loss: 1.5759e-04\n",
      "Epoch 169/500\n",
      "2578/2578 [==============================] - 0s 89us/step - loss: 7.8876e-05\n",
      "Epoch 170/500\n",
      "2578/2578 [==============================] - 0s 80us/step - loss: 6.0853e-05\n",
      "Epoch 171/500\n",
      "2578/2578 [==============================] - 0s 91us/step - loss: 5.6585e-05\n",
      "Epoch 172/500\n",
      "2578/2578 [==============================] - 0s 80us/step - loss: 6.0273e-05\n",
      "Epoch 173/500\n",
      "2578/2578 [==============================] - 0s 97us/step - loss: 5.2796e-05\n",
      "Epoch 174/500\n",
      "2578/2578 [==============================] - 0s 74us/step - loss: 5.5977e-05\n",
      "Epoch 175/500\n",
      "2578/2578 [==============================] - 0s 75us/step - loss: 1.1194e-04\n",
      "Epoch 176/500\n",
      "2578/2578 [==============================] - 0s 90us/step - loss: 1.4354e-04\n",
      "Epoch 177/500\n",
      "2578/2578 [==============================] - 0s 78us/step - loss: 1.2087e-04\n",
      "Epoch 178/500\n",
      "2578/2578 [==============================] - 0s 81us/step - loss: 1.4215e-04\n",
      "Epoch 179/500\n",
      "2578/2578 [==============================] - 0s 79us/step - loss: 1.3845e-04\n",
      "Epoch 180/500\n",
      "2578/2578 [==============================] - 0s 79us/step - loss: 1.1026e-04\n",
      "Epoch 181/500\n",
      "2578/2578 [==============================] - 0s 65us/step - loss: 8.4990e-05\n",
      "Epoch 182/500\n",
      "2578/2578 [==============================] - 0s 79us/step - loss: 2.9606e-04\n",
      "Epoch 183/500\n",
      "2578/2578 [==============================] - 0s 62us/step - loss: 1.2425e-04\n",
      "Epoch 184/500\n",
      "2578/2578 [==============================] - 0s 86us/step - loss: 8.0430e-05\n",
      "Epoch 185/500\n",
      "2578/2578 [==============================] - 0s 71us/step - loss: 4.7166e-05\n",
      "Epoch 186/500\n",
      "2578/2578 [==============================] - 0s 62us/step - loss: 6.1004e-05\n",
      "Epoch 187/500\n",
      "2578/2578 [==============================] - 0s 77us/step - loss: 9.5718e-05\n",
      "Epoch 188/500\n",
      "2578/2578 [==============================] - 0s 64us/step - loss: 1.7700e-04\n",
      "Epoch 189/500\n",
      "2578/2578 [==============================] - 0s 73us/step - loss: 7.4814e-05\n",
      "Epoch 190/500\n",
      "2578/2578 [==============================] - 0s 65us/step - loss: 8.6698e-05\n",
      "Epoch 191/500\n",
      "2578/2578 [==============================] - 0s 61us/step - loss: 1.0856e-04\n",
      "Epoch 192/500\n",
      "2578/2578 [==============================] - 0s 71us/step - loss: 2.0857e-04\n",
      "Epoch 193/500\n",
      "2578/2578 [==============================] - 0s 60us/step - loss: 1.5181e-04\n",
      "Epoch 194/500\n",
      "2578/2578 [==============================] - 0s 70us/step - loss: 1.0243e-04\n",
      "Epoch 195/500\n",
      "2578/2578 [==============================] - 0s 72us/step - loss: 1.8077e-04\n",
      "Epoch 196/500\n",
      "2578/2578 [==============================] - 0s 62us/step - loss: 1.8003e-04\n",
      "Epoch 197/500\n",
      "2578/2578 [==============================] - 0s 60us/step - loss: 1.6419e-04\n",
      "Epoch 198/500\n",
      "2578/2578 [==============================] - 0s 75us/step - loss: 2.7967e-04\n",
      "Epoch 199/500\n",
      "2578/2578 [==============================] - 0s 58us/step - loss: 1.5139e-04\n",
      "Epoch 200/500\n",
      "2578/2578 [==============================] - 0s 58us/step - loss: 1.8223e-04\n",
      "Epoch 201/500\n",
      "2578/2578 [==============================] - 0s 60us/step - loss: 2.2882e-04\n",
      "Epoch 202/500\n",
      "2578/2578 [==============================] - 0s 49us/step - loss: 1.4755e-04\n",
      "Epoch 203/500\n",
      "2578/2578 [==============================] - 0s 56us/step - loss: 1.1222e-04\n",
      "Epoch 204/500\n",
      "2578/2578 [==============================] - 0s 57us/step - loss: 9.9348e-05\n",
      "Epoch 205/500\n",
      "2578/2578 [==============================] - 0s 55us/step - loss: 1.3286e-04\n",
      "Epoch 206/500\n",
      "2578/2578 [==============================] - 0s 54us/step - loss: 2.2939e-04\n",
      "Epoch 207/500\n",
      "2578/2578 [==============================] - 0s 59us/step - loss: 1.6252e-04\n",
      "Epoch 208/500\n",
      "2578/2578 [==============================] - 0s 57us/step - loss: 1.8171e-04\n",
      "Epoch 209/500\n",
      "2578/2578 [==============================] - 0s 48us/step - loss: 1.8257e-04\n",
      "Epoch 210/500\n",
      "2578/2578 [==============================] - 0s 48us/step - loss: 1.9401e-04\n",
      "Epoch 211/500\n",
      "2578/2578 [==============================] - 0s 49us/step - loss: 1.2784e-04\n",
      "Epoch 212/500\n",
      "2578/2578 [==============================] - 0s 60us/step - loss: 2.1624e-04\n",
      "Epoch 213/500\n",
      "2578/2578 [==============================] - 0s 51us/step - loss: 2.0737e-04\n",
      "Epoch 214/500\n",
      "2578/2578 [==============================] - 0s 58us/step - loss: 1.5755e-04\n",
      "Epoch 215/500\n",
      "2578/2578 [==============================] - 0s 60us/step - loss: 3.6488e-04\n",
      "Epoch 216/500\n",
      "2578/2578 [==============================] - 0s 48us/step - loss: 2.9008e-04\n",
      "Epoch 217/500\n",
      "2578/2578 [==============================] - 0s 56us/step - loss: 1.5751e-04\n",
      "Epoch 218/500\n",
      "2578/2578 [==============================] - 0s 68us/step - loss: 1.2585e-04\n",
      "Epoch 219/500\n",
      "2578/2578 [==============================] - 0s 48us/step - loss: 1.7365e-04\n",
      "Epoch 220/500\n",
      "2578/2578 [==============================] - 0s 46us/step - loss: 9.0204e-05\n",
      "Epoch 221/500\n",
      "2578/2578 [==============================] - 0s 60us/step - loss: 1.4671e-04\n",
      "Epoch 222/500\n",
      "2578/2578 [==============================] - 0s 50us/step - loss: 1.2417e-04\n",
      "Epoch 223/500\n",
      "2578/2578 [==============================] - 0s 52us/step - loss: 5.0135e-04\n",
      "Epoch 224/500\n",
      "2578/2578 [==============================] - 0s 49us/step - loss: 1.7043e-04\n",
      "Epoch 225/500\n",
      "2578/2578 [==============================] - 0s 49us/step - loss: 1.3985e-04\n",
      "Epoch 226/500\n",
      "2578/2578 [==============================] - 0s 59us/step - loss: 1.6351e-04\n",
      "Epoch 227/500\n",
      "2578/2578 [==============================] - 0s 64us/step - loss: 1.1542e-04\n",
      "Epoch 228/500\n",
      "2578/2578 [==============================] - 0s 47us/step - loss: 1.0253e-04\n",
      "Epoch 229/500\n",
      "2578/2578 [==============================] - 0s 74us/step - loss: 1.7359e-04\n",
      "Epoch 230/500\n",
      "2578/2578 [==============================] - 0s 40us/step - loss: 1.6164e-04\n",
      "Epoch 231/500\n",
      "2578/2578 [==============================] - 0s 67us/step - loss: 1.3292e-04\n",
      "Epoch 232/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 1.9840e-04\n",
      "Epoch 233/500\n",
      "2578/2578 [==============================] - 0s 42us/step - loss: 8.6266e-05\n",
      "Epoch 234/500\n",
      "2578/2578 [==============================] - 0s 46us/step - loss: 6.9591e-05\n",
      "Epoch 235/500\n",
      "2578/2578 [==============================] - 0s 41us/step - loss: 9.5457e-05\n",
      "Epoch 236/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.4777e-04\n",
      "Epoch 237/500\n",
      "2578/2578 [==============================] - 0s 50us/step - loss: 1.0513e-04\n",
      "Epoch 238/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.5625e-04\n",
      "Epoch 239/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.8411e-04\n",
      "Epoch 240/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.6211e-04\n",
      "Epoch 241/500\n",
      "2578/2578 [==============================] - 0s 57us/step - loss: 2.1474e-04\n",
      "Epoch 242/500\n",
      "2578/2578 [==============================] - 0s 48us/step - loss: 4.3429e-04\n",
      "Epoch 243/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 3.4050e-04\n",
      "Epoch 244/500\n",
      "2578/2578 [==============================] - 0s 64us/step - loss: 2.2464e-04\n",
      "Epoch 245/500\n",
      "2578/2578 [==============================] - 0s 52us/step - loss: 4.9288e-04\n",
      "Epoch 246/500\n",
      "2578/2578 [==============================] - 0s 54us/step - loss: 5.5591e-04\n",
      "Epoch 247/500\n",
      "2578/2578 [==============================] - 0s 64us/step - loss: 3.9285e-04\n",
      "Epoch 248/500\n",
      "2578/2578 [==============================] - 0s 64us/step - loss: 1.5359e-04\n",
      "Epoch 249/500\n",
      "2578/2578 [==============================] - 0s 49us/step - loss: 2.7677e-04\n",
      "Epoch 250/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.1266e-04\n",
      "Epoch 251/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 5.5699e-05\n",
      "Epoch 252/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 5.2240e-05\n",
      "Epoch 253/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 9.1711e-05\n",
      "Epoch 254/500\n",
      "2578/2578 [==============================] - 0s 42us/step - loss: 1.0743e-04\n",
      "Epoch 255/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 1.8088e-04\n",
      "Epoch 256/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.3554e-04\n",
      "Epoch 257/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.4781e-04\n",
      "Epoch 258/500\n",
      "2578/2578 [==============================] - 0s 52us/step - loss: 1.8072e-04\n",
      "Epoch 259/500\n",
      "2578/2578 [==============================] - 0s 54us/step - loss: 2.6096e-04\n",
      "Epoch 260/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 3.7181e-04\n",
      "Epoch 261/500\n",
      "2578/2578 [==============================] - 0s 61us/step - loss: 2.0694e-04\n",
      "Epoch 262/500\n",
      "2578/2578 [==============================] - 0s 52us/step - loss: 2.7390e-04\n",
      "Epoch 263/500\n",
      "2578/2578 [==============================] - 0s 44us/step - loss: 1.5300e-04\n",
      "Epoch 264/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 1.8311e-04\n",
      "Epoch 265/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.0304e-04\n",
      "Epoch 266/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.6765e-04\n",
      "Epoch 267/500\n",
      "2578/2578 [==============================] - 0s 45us/step - loss: 1.8639e-04\n",
      "Epoch 268/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.6091e-04\n",
      "Epoch 269/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.7666e-04\n",
      "Epoch 270/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 7.0861e-04\n",
      "Epoch 271/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.9595e-04\n",
      "Epoch 272/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 3.0068e-04\n",
      "Epoch 273/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.1553e-04\n",
      "Epoch 274/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.2051e-04\n",
      "Epoch 275/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.5900e-04\n",
      "Epoch 276/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 2.9994e-04\n",
      "Epoch 277/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 3.9853e-04\n",
      "Epoch 278/500\n",
      "2578/2578 [==============================] - 0s 46us/step - loss: 1.7748e-04\n",
      "Epoch 279/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.1093e-04\n",
      "Epoch 280/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 3.3320e-04\n",
      "Epoch 281/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 3.0778e-04\n",
      "Epoch 282/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.6262e-04\n",
      "Epoch 283/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.2229e-04\n",
      "Epoch 284/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.4735e-04\n",
      "Epoch 285/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.3630e-04\n",
      "Epoch 286/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.4200e-04\n",
      "Epoch 287/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.3264e-04\n",
      "Epoch 288/500\n",
      "2578/2578 [==============================] - 0s 48us/step - loss: 1.2608e-04\n",
      "Epoch 289/500\n",
      "2578/2578 [==============================] - 0s 41us/step - loss: 2.0779e-04\n",
      "Epoch 290/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 7.0869e-05\n",
      "Epoch 291/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.2656e-04\n",
      "Epoch 292/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.2983e-04\n",
      "Epoch 293/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.5206e-04\n",
      "Epoch 294/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.8194e-04\n",
      "Epoch 295/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 3.7031e-04\n",
      "Epoch 296/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 3.3087e-04\n",
      "Epoch 297/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 2.6373e-04\n",
      "Epoch 298/500\n",
      "2578/2578 [==============================] - 0s 47us/step - loss: 2.3521e-04\n",
      "Epoch 299/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.8981e-04\n",
      "Epoch 300/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 3.4140e-04\n",
      "Epoch 301/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 2.6385e-04\n",
      "Epoch 302/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 3.4104e-04\n",
      "Epoch 303/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 2.3661e-04\n",
      "Epoch 304/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.7836e-04\n",
      "Epoch 305/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.2375e-04\n",
      "Epoch 306/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.1200e-04\n",
      "Epoch 307/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.4862e-04\n",
      "Epoch 308/500\n",
      "2578/2578 [==============================] - 0s 44us/step - loss: 1.3909e-04\n",
      "Epoch 309/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.5631e-04\n",
      "Epoch 310/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 1.8848e-04\n",
      "Epoch 311/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 2.2856e-04\n",
      "Epoch 312/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 3.0503e-04\n",
      "Epoch 313/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 2.0848e-04\n",
      "Epoch 314/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 2.4743e-04\n",
      "Epoch 315/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 1.8574e-04\n",
      "Epoch 316/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.4297e-04\n",
      "Epoch 317/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 2.0796e-04\n",
      "Epoch 318/500\n",
      "2578/2578 [==============================] - 0s 53us/step - loss: 1.2872e-04\n",
      "Epoch 319/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 8.1273e-05\n",
      "Epoch 320/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.0932e-04\n",
      "Epoch 321/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 2.0084e-04\n",
      "Epoch 322/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.0921e-04\n",
      "Epoch 323/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 3.2025e-04\n",
      "Epoch 324/500\n",
      "2578/2578 [==============================] - 0s 41us/step - loss: 2.4893e-04\n",
      "Epoch 325/500\n",
      "2578/2578 [==============================] - 0s 47us/step - loss: 2.6358e-04\n",
      "Epoch 326/500\n",
      "2578/2578 [==============================] - 0s 66us/step - loss: 1.8482e-04\n",
      "Epoch 327/500\n",
      "2578/2578 [==============================] - 0s 65us/step - loss: 2.5571e-04\n",
      "Epoch 328/500\n",
      "2578/2578 [==============================] - 0s 41us/step - loss: 3.3401e-04\n",
      "Epoch 329/500\n",
      "2578/2578 [==============================] - 0s 40us/step - loss: 1.8153e-04\n",
      "Epoch 330/500\n",
      "2578/2578 [==============================] - 0s 45us/step - loss: 1.3828e-04\n",
      "Epoch 331/500\n",
      "2578/2578 [==============================] - 0s 41us/step - loss: 1.5749e-04\n",
      "Epoch 332/500\n",
      "2578/2578 [==============================] - 0s 40us/step - loss: 1.1146e-04\n",
      "Epoch 333/500\n",
      "2578/2578 [==============================] - 0s 54us/step - loss: 1.4802e-04\n",
      "Epoch 334/500\n",
      "2578/2578 [==============================] - 0s 53us/step - loss: 1.2049e-04\n",
      "Epoch 335/500\n",
      "2578/2578 [==============================] - 0s 58us/step - loss: 1.3716e-04\n",
      "Epoch 336/500\n",
      "2578/2578 [==============================] - 0s 51us/step - loss: 1.4801e-04\n",
      "Epoch 337/500\n",
      "2578/2578 [==============================] - 0s 45us/step - loss: 1.2704e-04\n",
      "Epoch 338/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 4.3657e-04\n",
      "Epoch 339/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 3.2980e-04\n",
      "Epoch 340/500\n",
      "2578/2578 [==============================] - 0s 79us/step - loss: 3.1560e-04\n",
      "Epoch 341/500\n",
      "2578/2578 [==============================] - 0s 45us/step - loss: 4.0674e-04\n",
      "Epoch 342/500\n",
      "2578/2578 [==============================] - 0s 45us/step - loss: 3.1766e-04\n",
      "Epoch 343/500\n",
      "2578/2578 [==============================] - 0s 50us/step - loss: 2.0612e-04\n",
      "Epoch 344/500\n",
      "2578/2578 [==============================] - 0s 68us/step - loss: 1.1594e-04\n",
      "Epoch 345/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.0505e-04\n",
      "Epoch 346/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.0247e-04\n",
      "Epoch 347/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 6.8627e-05\n",
      "Epoch 348/500\n",
      "2578/2578 [==============================] - 0s 40us/step - loss: 1.1065e-04\n",
      "Epoch 349/500\n",
      "2578/2578 [==============================] - 0s 51us/step - loss: 7.1762e-05\n",
      "Epoch 350/500\n",
      "2578/2578 [==============================] - 0s 41us/step - loss: 1.2690e-04\n",
      "Epoch 351/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 2.1902e-04\n",
      "Epoch 352/500\n",
      "2578/2578 [==============================] - 0s 57us/step - loss: 1.8300e-04\n",
      "Epoch 353/500\n",
      "2578/2578 [==============================] - 0s 52us/step - loss: 1.4403e-04\n",
      "Epoch 354/500\n",
      "2578/2578 [==============================] - 0s 46us/step - loss: 1.2046e-04\n",
      "Epoch 355/500\n",
      "2578/2578 [==============================] - 0s 45us/step - loss: 1.6851e-04\n",
      "Epoch 356/500\n",
      "2578/2578 [==============================] - 0s 73us/step - loss: 9.6792e-05\n",
      "Epoch 357/500\n",
      "2578/2578 [==============================] - 0s 56us/step - loss: 1.1019e-04\n",
      "Epoch 358/500\n",
      "2578/2578 [==============================] - 0s 43us/step - loss: 5.5799e-05\n",
      "Epoch 359/500\n",
      "2578/2578 [==============================] - 0s 47us/step - loss: 1.6538e-04\n",
      "Epoch 360/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 3.7350e-04\n",
      "Epoch 361/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 3.1123e-04\n",
      "Epoch 362/500\n",
      "2578/2578 [==============================] - 0s 40us/step - loss: 1.9577e-04\n",
      "Epoch 363/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.3554e-04\n",
      "Epoch 364/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 3.7048e-04\n",
      "Epoch 365/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.9997e-04\n",
      "Epoch 366/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 3.6280e-04\n",
      "Epoch 367/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 2.7666e-04\n",
      "Epoch 368/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.2749e-04\n",
      "Epoch 369/500\n",
      "2578/2578 [==============================] - 0s 53us/step - loss: 1.4561e-04\n",
      "Epoch 370/500\n",
      "2578/2578 [==============================] - 0s 44us/step - loss: 2.3006e-04\n",
      "Epoch 371/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.0802e-04\n",
      "Epoch 372/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.1745e-04\n",
      "Epoch 373/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 2.9723e-04\n",
      "Epoch 374/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 4.9966e-04\n",
      "Epoch 375/500\n",
      "2578/2578 [==============================] - 0s 40us/step - loss: 6.4981e-04\n",
      "Epoch 376/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 3.9583e-04\n",
      "Epoch 377/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.2027e-04\n",
      "Epoch 378/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.5310e-04\n",
      "Epoch 379/500\n",
      "2578/2578 [==============================] - 0s 53us/step - loss: 2.2749e-04\n",
      "Epoch 380/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.2016e-04\n",
      "Epoch 381/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.0466e-04\n",
      "Epoch 382/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 6.0682e-05\n",
      "Epoch 383/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 7.3082e-05\n",
      "Epoch 384/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.1435e-04\n",
      "Epoch 385/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.4070e-04\n",
      "Epoch 386/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 1.5982e-04\n",
      "Epoch 387/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 2.3715e-04\n",
      "Epoch 388/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.4944e-04\n",
      "Epoch 389/500\n",
      "2578/2578 [==============================] - 0s 50us/step - loss: 1.7755e-04\n",
      "Epoch 390/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 2.2705e-04\n",
      "Epoch 391/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 9.4760e-05\n",
      "Epoch 392/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 2.7613e-04\n",
      "Epoch 393/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.9481e-04\n",
      "Epoch 394/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.4248e-04\n",
      "Epoch 395/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 8.7651e-05\n",
      "Epoch 396/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 1.2103e-04\n",
      "Epoch 397/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 7.7045e-05\n",
      "Epoch 398/500\n",
      "2578/2578 [==============================] - 0s 45us/step - loss: 6.8463e-05\n",
      "Epoch 399/500\n",
      "2578/2578 [==============================] - 0s 40us/step - loss: 2.0788e-04\n",
      "Epoch 400/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 2.3994e-04\n",
      "Epoch 401/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 4.3988e-04\n",
      "Epoch 402/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 3.7247e-04\n",
      "Epoch 403/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.1937e-04\n",
      "Epoch 404/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.4862e-04\n",
      "Epoch 405/500\n",
      "2578/2578 [==============================] - 0s 41us/step - loss: 2.3726e-04\n",
      "Epoch 406/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 3.8268e-04\n",
      "Epoch 407/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 3.2301e-04\n",
      "Epoch 408/500\n",
      "2578/2578 [==============================] - 0s 55us/step - loss: 1.5459e-04\n",
      "Epoch 409/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.1541e-04\n",
      "Epoch 410/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 7.0235e-05\n",
      "Epoch 411/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 8.8086e-05\n",
      "Epoch 412/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 1.3547e-04\n",
      "Epoch 413/500\n",
      "2578/2578 [==============================] - 0s 40us/step - loss: 1.7045e-04\n",
      "Epoch 414/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.7874e-04\n",
      "Epoch 415/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.2178e-04\n",
      "Epoch 416/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.0274e-04\n",
      "Epoch 417/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 3.0835e-04\n",
      "Epoch 418/500\n",
      "2578/2578 [==============================] - 0s 51us/step - loss: 2.2978e-04\n",
      "Epoch 419/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 1.4210e-04\n",
      "Epoch 420/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 2.4724e-04\n",
      "Epoch 421/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.6770e-04\n",
      "Epoch 422/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 1.7522e-04\n",
      "Epoch 423/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 4.1717e-04\n",
      "Epoch 424/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 2.8812e-04\n",
      "Epoch 425/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 2.1994e-04\n",
      "Epoch 426/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 2.0874e-04\n",
      "Epoch 427/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 9.0299e-05\n",
      "Epoch 428/500\n",
      "2578/2578 [==============================] - 0s 48us/step - loss: 2.2437e-04\n",
      "Epoch 429/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 3.9837e-04\n",
      "Epoch 430/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 4.7919e-04\n",
      "Epoch 431/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 2.7955e-04\n",
      "Epoch 432/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 8.9311e-05\n",
      "Epoch 433/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 8.7156e-05\n",
      "Epoch 434/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 6.8875e-05\n",
      "Epoch 435/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.2534e-04\n",
      "Epoch 436/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 7.5835e-05\n",
      "Epoch 437/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.7609e-04\n",
      "Epoch 438/500\n",
      "2578/2578 [==============================] - 0s 45us/step - loss: 2.2646e-04\n",
      "Epoch 439/500\n",
      "2578/2578 [==============================] - 0s 48us/step - loss: 2.8254e-04\n",
      "Epoch 440/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 4.5024e-04\n",
      "Epoch 441/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 7.4839e-04\n",
      "Epoch 442/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 5.0616e-04\n",
      "Epoch 443/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 2.5120e-04\n",
      "Epoch 444/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 2.1379e-04\n",
      "Epoch 445/500\n",
      "2578/2578 [==============================] - 0s 53us/step - loss: 1.0253e-04\n",
      "Epoch 446/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 9.0692e-05\n",
      "Epoch 447/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.0502e-04\n",
      "Epoch 448/500\n",
      "2578/2578 [==============================] - 0s 48us/step - loss: 1.0576e-04\n",
      "Epoch 449/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 3.4921e-04\n",
      "Epoch 450/500\n",
      "2578/2578 [==============================] - 0s 40us/step - loss: 3.9073e-04\n",
      "Epoch 451/500\n",
      "2578/2578 [==============================] - 0s 45us/step - loss: 2.0934e-04\n",
      "Epoch 452/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.0920e-04\n",
      "Epoch 453/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.7113e-04\n",
      "Epoch 454/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.4852e-04\n",
      "Epoch 455/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.2460e-04\n",
      "Epoch 456/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 7.8252e-05\n",
      "Epoch 457/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 8.3462e-05\n",
      "Epoch 458/500\n",
      "2578/2578 [==============================] - 0s 47us/step - loss: 5.2608e-05\n",
      "Epoch 459/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 5.6585e-05\n",
      "Epoch 460/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 7.1482e-05\n",
      "Epoch 461/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.4438e-04\n",
      "Epoch 462/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 3.2405e-04\n",
      "Epoch 463/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 2.7002e-04\n",
      "Epoch 464/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.9185e-04\n",
      "Epoch 465/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 4.2369e-04\n",
      "Epoch 466/500\n",
      "2578/2578 [==============================] - 0s 40us/step - loss: 5.0441e-04\n",
      "Epoch 467/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 5.4972e-04\n",
      "Epoch 468/500\n",
      "2578/2578 [==============================] - 0s 52us/step - loss: 3.9472e-04\n",
      "Epoch 469/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.1942e-04\n",
      "Epoch 470/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.5473e-04\n",
      "Epoch 471/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.2916e-04\n",
      "Epoch 472/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 9.0218e-05\n",
      "Epoch 473/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.0381e-04\n",
      "Epoch 474/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 1.3691e-04\n",
      "Epoch 475/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 9.6285e-05\n",
      "Epoch 476/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 8.3142e-05\n",
      "Epoch 477/500\n",
      "2578/2578 [==============================] - 0s 48us/step - loss: 4.7416e-05\n",
      "Epoch 478/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 9.4704e-05\n",
      "Epoch 479/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 2.4680e-04\n",
      "Epoch 480/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 8.9640e-05\n",
      "Epoch 481/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 1.1091e-04\n",
      "Epoch 482/500\n",
      "2578/2578 [==============================] - 0s 40us/step - loss: 1.7276e-04\n",
      "Epoch 483/500\n",
      "2578/2578 [==============================] - 0s 39us/step - loss: 1.4796e-04\n",
      "Epoch 484/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.2618e-04\n",
      "Epoch 485/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.1688e-04\n",
      "Epoch 486/500\n",
      "2578/2578 [==============================] - 0s 35us/step - loss: 5.6131e-04\n",
      "Epoch 487/500\n",
      "2578/2578 [==============================] - 0s 34us/step - loss: 5.9444e-04\n",
      "Epoch 488/500\n",
      "2578/2578 [==============================] - 0s 44us/step - loss: 6.7845e-04\n",
      "Epoch 489/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.4335e-04\n",
      "Epoch 490/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 1.7445e-04\n",
      "Epoch 491/500\n",
      "2578/2578 [==============================] - 0s 36us/step - loss: 7.6808e-05\n",
      "Epoch 492/500\n",
      "2578/2578 [==============================] - 0s 37us/step - loss: 5.7803e-05\n",
      "Epoch 493/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 4.5328e-05\n",
      "Epoch 494/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.3500e-04\n",
      "Epoch 495/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.0738e-04\n",
      "Epoch 496/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 6.8553e-04\n",
      "Epoch 497/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 9.8892e-04\n",
      "Epoch 498/500\n",
      "2578/2578 [==============================] - 0s 53us/step - loss: 3.6083e-04\n",
      "Epoch 499/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 2.4218e-04\n",
      "Epoch 500/500\n",
      "2578/2578 [==============================] - 0s 38us/step - loss: 1.6218e-04\n",
      "input_1\n",
      "split_layer\n",
      "embedding_w_0\n",
      "embedding_w_1\n",
      "embedding_w_2\n",
      "embedding_w_3\n",
      "dot_1\n",
      "dot_2\n",
      "dot_3\n",
      "dot_4\n",
      "dot_5\n",
      "dot_6\n",
      "reshape_1\n",
      "embedding_b_0\n",
      "embedding_b_1\n",
      "reshape_3\n",
      "embedding_b_2\n",
      "reshape_5\n",
      "embedding_b_3\n",
      "reshape_7\n",
      "reshape_9\n",
      "reshape_11\n",
      "add_1\n",
      "add_2\n",
      "add_3\n",
      "add_4\n",
      "add_5\n",
      "add_6\n",
      "reshape_2\n",
      "reshape_4\n",
      "reshape_6\n",
      "reshape_8\n",
      "reshape_10\n",
      "reshape_12\n",
      "stack_layer\n",
      "squeeze_layer\n",
      " >>  HSCode\n",
      " >>  ShipmentDestination\n",
      " >>  ShipperPanjivaID\n",
      " >>  TransportMethod\n",
      "[ 1  7 17 29  9 26 27  6 22 24]\n",
      "     0                       1\n",
      "11  11  [[0.7499861552259196]]\n",
      "14  14  [[0.7573466493325038]]\n",
      "9    9  [[0.7830298534258961]]\n",
      "22  22  [[0.7854089497601148]]\n",
      "27  27  [[0.7890429820581304]]\n",
      "6    6  [[0.7894268338390987]]\n",
      "29  29  [[0.7904998499250802]]\n",
      "26  26  [[0.7981725551483493]]\n",
      "24  24  [[0.7992210245470734]]\n",
      "1    1  [[0.8111135842338713]]\n"
     ]
    }
   ],
   "source": [
    "get_initial_entity_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  7, 17, 29,  9, 26, 27,  6, 22, 24])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
